# üìÑ WHITEPAPER T√âCNICO  
## **Arquitetura de Compress√£o Acelerada por GPU com Deduplica√ß√£o Inteligente para Grandes Conjuntos de Arquivos**  
**Autor:** *[Daniel Anselmo]*  


---

# **Resumo Executivo**

Este whitepaper apresenta um sistema de compress√£o de arquivos de alta performance que combina **deduplica√ß√£o multin√≠vel**, **compress√£o LZ4 estendida acelerada por GPU**, **fallback otimizado para CPU**, e um **pipeline de processamento ass√≠ncrono** projetado para atingir throughput equivalente ou superior aos limites de I/O do ambiente (rede ou SSDs).

Em testes reais, o sistema demonstrou:

- **~9% de economia por deduplica√ß√£o**  
- **~25% de compress√£o l√≠quida** sobre dados p√≥s-dedup  
- Throughput sustentado de **~107 MB/s**, saturando rede gigabit  
- Opera√ß√£o eficiente tanto em GPUs NVIDIA quanto Intel  
- Redu√ß√£o total de ~**31% do espa√ßo** em backup de ~50 GB

O resultado √© uma solu√ß√£o √∫nica no mercado, combinando conceitos usados em data centers, engines de jogos AAA e sistemas de armazenamento distribu√≠do ‚Äî por√©m aplicada a backups de sistemas de arquivos reais.

---

# **1. Introdu√ß√£o**

A crescente demanda por armazenamento eficiente, junto √† necessidade de transportar grandes volumes de dados por redes limitadas, cria desafios que n√£o podem ser resolvidos apenas por compress√£o tradicional.  
Este projeto prop√µe uma solu√ß√£o inovadora baseada em:

- **Deduplica√ß√£o inteligente** para remover redund√¢ncias antes da compress√£o.  
- **Acelera√ß√£o por GPU** para atingir paralelismo de grau massivo.  
- **Algoritmo LZ4 estendido (LZ4_EXT3)**, compat√≠vel apenas internamente, otimizando janelas grandes e performance.  
- **Fallback CPU de alta velocidade**, usando Numba JIT.  
- **Pipeline ass√≠ncrono de alto throughput**, permitindo leitura, compress√£o e escrita simult√¢neas.

O objetivo √© criar um sistema capaz de **aproximar-se do limite f√≠sico da camada de I/O**, eliminando gargalos t√≠picos de compressores tradicionais.

---

# **2. Motiva√ß√£o**

Solu√ß√µes tradicionais de compress√£o apresentam limita√ß√µes claras:

| Desafio | Solu√ß√µes tradicionais | Limita√ß√µes |
|--------|------------------------|------------|
| Compress√£o em arquivos j√° comprimidos | LZ4, ZIP, Zstd | Ganho baixo, custo alto |
| Paraleliza√ß√£o | Multithread em CPU | Escala limitada pelo n√∫mero de n√∫cleos |
| Deduplica√ß√£o | Ferramentas externas | Alto custo de hashing |
| Grandes pastas | Processamento linear | I/O se torna gargalo |
| Acelera√ß√£o por GPU | Pouco utilizada | Estrutura√ß√£o complexa |

O projeto aqui apresentado aborda cada um desses gargalos simultaneamente, criando uma solu√ß√£o integrada, eficiente e escal√°vel.

---

# **3. Arquitetura Geral do Sistema**

A arquitetura consiste em tr√™s fases principais:





[ Fase 1: Deduplica√ß√£o ] ‚Üí [ Fase 2: Compress√£o GPU/CPU ] ‚Üí [ Fase 3: Escrita em Volumes ]

Cada fase √© executada com **pipelines paralelos**, evitando esperas desnecess√°rias e saturando os limites de hardware.

---

# **4. Fase 1 ‚Äî Deduplica√ß√£o Multin√≠vel**

## **4.1 Objetivos**
- Evitar compress√£o redundante.  
- Reduzir o volume de dados enviados √† GPU.  
- Minimizar I/O e uso de mem√≥ria.  

## **4.2 Estrat√©gia Multin√≠vel**

A deduplica√ß√£o ocorre em camadas progressivas:

1. **Filtro por tamanho**  
2. **Filtro por prefixo (primeiros bytes)**  
3. **Filtro por sufixo (√∫ltimos bytes)**  
4. **Filtro por bytes centrais**  
5. **Hashing GPU em lote (arquivos at√© 100 MB)**  
6. **Hashing incremental CPU para arquivos maiores**  
7. **Confirma√ß√£o final de duplicatas**  

## **4.3 Desempenho Observado**

- 25.053 arquivos analisados  
- 8.985 duplicatas reais removidas  
- Economia: **4,6 GB (~9%)** antes da compress√£o  

O uso da GPU permite hashing massivo, reduzindo drasticamente o conjunto de arquivos √∫nicos a serem comprimidos.

---

# **5. Fase 2 ‚Äî Compress√£o GPU LZ4_EXT3**

## **5.1 Motiva√ß√£o do LZ4_EXT3**

O algoritmo baseia-se no LZ4 tradicional, por√©m com adapta√ß√µes que:

- Aumentam a janela para **16 MB**, permitindo matches longos;  
- Utilizam **hash table expandida**, reduzindo colis√µes;  
- Empregam **lazy matching** e adaptive skip;  
- Operam em **frames independentes**, ideais para GPU.

## **5.2 Estrutura do Processamento GPU**

Cada opera√ß√£o de compress√£o utiliza:

- **Batch de at√© 70 frames** de 16 MB  
- Input/output em **pinned memory**  
- Hash tables de ‚âà28 MB por frame  
- Kernel OpenCL especializado com execu√ß√£o paralela massiva  
- Transfer√™ncias ass√≠ncronas entre host e GPU

## **5.3 Consumo de VRAM**

Para `batch = 70`:

- Input frames: 1120 MB  
- Output frames: 1124 MB  
- Hash tables: 1960 MB  
- **Total = 4,2 GB**

## **5.4 Resultados Observados**

- ~66% dos frames foram comprimidos  
- ~34% foram marcados como RAW  
- Taxa m√©dia de compress√£o: **~25%**  
- Throughput real: **~107 MB/s**  
- Limite observado: **rede gigabit**, n√£o CPU/GPU

A GPU opera abaixo de sua capacidade m√°xima ‚Äî o gargalo migra para a camada de I/O, o que √© ideal.

---

# **6. Fallback CPU LZ4_EXT3 (Numba JIT)**

A vers√£o CPU oferece:

- JIT otimizado para fun√ß√µes cr√≠ticas  
- Hash table multidimensional em NumPy  
- Multi-thread paralelizado com `ThreadPoolExecutor`  
- Desempenho robusto para sistemas sem GPU

O fallback mant√©m a compatibilidade total com o formato de compress√£o da GPU.

---

# **7. Pipeline Ass√≠ncrono de Alto Throughput**

O pipeline √© composto por tr√™s filas principais:

[ LEITURA ] ‚Üí [ COMPRESS√ÉO (GPU/CPU) ] ‚Üí [ ESCRITA ]


Cada etapa:

- Opera com batch buffers  
- N√£o bloqueia a etapa seguinte  
- Suporta m√∫ltiplas GPUs  
- Foi projetada para saturar o dispositivo de sa√≠da (SSD/rede)

Esse modelo se inspira em:

- NVIDIA nvCOMP  
- Microsoft DirectStorage  
- Arquiteturas de engines AAA

---

# **8. Resultados de Testes Reais**

Um backup real de ~50,7 GB gerou:

| Etapa | Resultado |
|-------|-----------|
| Deduplica√ß√£o | ‚Äì4,6 GB (9% economia) |
| Compress√£o | ‚Äì11,6 GB (~25% economia adicional) |
| Tamanho final | ~34,6 GB |
| Economia total | **~31%** |
| Throughput | **~107 MB/s** |

O throughput atingiu o **limite da rede gigabit**, validando a efici√™ncia da arquitetura.

---

# **9. Compara√ß√µes com Tecnologias Existentes**

| Tecnologia | Similaridade | Diferen√ßa |
|------------|--------------|-----------|
| **NVIDIA nvCOMP** | Compress√£o GPU em batch | N√£o possui dedup + pipeline completo |
| **GDeflate (DirectStorage)** | Formato paraleliz√°vel | Focado em jogos |
| **Oodle Kraken** | Otimiza√ß√µes LZ | N√£o usa GPU |
| **Zstd Long** | Matches longos | N√£o usa GPU |
| **Shredder** | Dedup em GPU | N√£o possui compress√£o |

Nenhuma tecnologia atual combina **deduplica√ß√£o, compress√£o GPU, fallback CPU e pipeline ass√≠ncrono** como este projeto.

---

# **10. Conclus√£o**

Este sistema demonstra:

1. A viabilidade e efici√™ncia de **combinar deduplica√ß√£o + compress√£o GPU**.  
2. A capacidade de operar no **limite f√≠sico da camada de I/O**.  
3. Um conjunto de t√©cnicas compar√°vel √†s melhores tecnologias do mercado.  
4. Aplica√ß√£o pr√°tica em backups reais, com ganhos mensur√°veis e imediatos.

A arquitetura √© extens√≠vel, robusta e adequada a ambientes corporativos e pessoais.


---
Para Gerar o seu EXE standalone:
pyinstaller --name "LZ4 GPU Explorer CLI" --onefile explorer.py --add-data "config.txt;."
